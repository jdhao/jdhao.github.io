<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GCP on jdhao's digital space</title><link>https://jdhao.github.io/tags/gcp/</link><description>Recent content in GCP on jdhao's digital space</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2017 - 2025 ❤️ jdhao</copyright><lastBuildDate>Tue, 08 Oct 2024 23:28:16 +0200</lastBuildDate><atom:link href="https://jdhao.github.io/tags/gcp/index.xml" rel="self" type="application/rss+xml"/><item><title>Retry for Google Cloud Client</title><link>https://jdhao.github.io/2024/10/08/gcloud_client_retry/</link><pubDate>Tue, 08 Oct 2024 23:28:16 +0200</pubDate><guid>https://jdhao.github.io/2024/10/08/gcloud_client_retry/</guid><description>&lt;p>When we use one of the google cloud python clients to communicate with GCP,
there may be errors occurring sometime calling the client API methods.&lt;/p></description></item><item><title>Make Python logging Work in GCP</title><link>https://jdhao.github.io/2024/09/20/python_logging_in_gcp/</link><pubDate>Fri, 20 Sep 2024 18:30:19 +0200</pubDate><guid>https://jdhao.github.io/2024/09/20/python_logging_in_gcp/</guid><description>&lt;p>When deploying a Python application to GCP Kuberntes Engine,
we may see issues that the &lt;a href="https://stackoverflow.com/q/75361466/6064933" target="_blank">logging level is not correct&lt;/a> in the cloud logging explorer.
In order for the &lt;a href="https://docs.python.org/3/library/logging.html" target="_blank">Python logging package&lt;/a> to work with GCP, we need some additional configurations.&lt;/p></description></item><item><title>Liveness and Readiness Check in Kubernetes</title><link>https://jdhao.github.io/2024/09/20/kubernetes_liveness_readiness_check/</link><pubDate>Fri, 20 Sep 2024 18:27:14 +0200</pubDate><guid>https://jdhao.github.io/2024/09/20/kubernetes_liveness_readiness_check/</guid><description>Readiness and Liveness probe # The readiness probe checks if the service in pod can accept traffic. Kubernetes will remove the pod if the readiness probe fails.
The liveness probe is used to check whether the pod is still alive and functioning. If the liveness check fails, the pod will be restarted by Kubernetes.
Types of readiness and liveness probe # We can use HTTP, command or TCP probe.
Get configuration for liveness and readiness # We can run the following command to get the pod configuration:</description></item><item><title>Notes on Using GCP Logging</title><link>https://jdhao.github.io/2024/09/16/gcp_logging_notes/</link><pubDate>Mon, 16 Sep 2024 23:23:44 +0200</pubDate><guid>https://jdhao.github.io/2024/09/16/gcp_logging_notes/</guid><description>Use the SEARCH() function with care # In the GCP Log Explorer, if you type some thing in the search bar without quote, the SEARCH() method is used.
The SEARCH() function is case insensitive. Note also that SEARCH() function uses text analyzer to tokenize the string. The SEARCH() function performs exact matches, not partial matching. So SEARCH(&amp;quot;world&amp;quot;) will not be able to match worldwide. Another example, suppose in some of the log entries, you may have &amp;ldquo;today is 202408180429&amp;rdquo;, if you use SEARCH(&amp;quot;20240818&amp;quot;), you will find nothing matching, which you may not expect.</description></item><item><title>Google Cloud Storage Usage</title><link>https://jdhao.github.io/2024/07/10/gcloud_storage_usage/</link><pubDate>Wed, 10 Jul 2024 22:42:29 +0200</pubDate><guid>https://jdhao.github.io/2024/07/10/gcloud_storage_usage/</guid><description>&lt;p>Some notes on using the &lt;a href="https://cloud.google.com/storage/docs/introduction#quickstarts" target="_blank">Google Cloud storage&lt;/a>.&lt;/p></description></item><item><title>How to Download Files from Google Cloud Storage in the Databricks Workspace Notebook</title><link>https://jdhao.github.io/2023/11/21/databricks-notebook-gcloud-storage-download/</link><pubDate>Tue, 21 Nov 2023 23:56:36 +0100</pubDate><guid>https://jdhao.github.io/2023/11/21/databricks-notebook-gcloud-storage-download/</guid><description>&lt;p>In this post, I want to share the complete process and setup to download files from GCP in a Databricks workspace notebook.
Since the notebook itself is non-interactive when you run the shell command,
the setup process is a bit different from the normal GCP authentication.&lt;/p></description></item></channel></rss>