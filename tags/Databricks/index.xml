<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Databricks on jdhao's digital space</title><link>https://jdhao.github.io/tags/Databricks/</link><description>Recent content in Databricks on jdhao's digital space</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>jdhao</copyright><lastBuildDate>Tue, 21 Nov 2023 23:56:36 +0100</lastBuildDate><atom:link href="https://jdhao.github.io/tags/Databricks/index.xml" rel="self" type="application/rss+xml"/><item><title>How to Download Files from Google Cloud Storage in the Databricks Workspace Notebook</title><link>https://jdhao.github.io/2023/11/21/databricks-notebook-gcloud-storage-download/</link><pubDate>Tue, 21 Nov 2023 23:56:36 +0100</pubDate><guid>https://jdhao.github.io/2023/11/21/databricks-notebook-gcloud-storage-download/</guid><description>&lt;p>In this post, I want to share the complete process and setup to download files from GCP in a Databricks workspace notebook.
Since the notebook itself is non-interactive when you run the shell command,
the setup process is a bit different from the normal GCP authentication.&lt;/p></description></item><item><title>Databricks Cli Usage</title><link>https://jdhao.github.io/2023/11/21/databricks-cli-usage/</link><pubDate>Tue, 21 Nov 2023 23:49:06 +0100</pubDate><guid>https://jdhao.github.io/2023/11/21/databricks-cli-usage/</guid><description>&lt;p>We can use the &lt;a href="https://learn.microsoft.com/en-us/azure/databricks/dev-tools/cli/">Databricks cli&lt;/a> to interact with Databricks workspaces programmatically on the command line.
In this post, I want to share simple usage about Databricks cli.&lt;/p></description></item><item><title>Working with Databricks Workspace Files</title><link>https://jdhao.github.io/2023/11/18/databricks-workspace-files/</link><pubDate>Sat, 18 Nov 2023 22:34:20 +0100</pubDate><guid>https://jdhao.github.io/2023/11/18/databricks-workspace-files/</guid><description>&lt;p>Some observation and finding in working with Databricks workspace files.&lt;/p></description></item><item><title>Databricks Init Scripts</title><link>https://jdhao.github.io/2023/10/21/databricks-init-scripts/</link><pubDate>Sat, 21 Oct 2023 00:54:33 +0200</pubDate><guid>https://jdhao.github.io/2023/10/21/databricks-init-scripts/</guid><description/></item><item><title>File Systems in Databricks</title><link>https://jdhao.github.io/2023/10/03/databricks-dbfs-and-other-filesystem/</link><pubDate>Tue, 03 Oct 2023 15:35:28 +0200</pubDate><guid>https://jdhao.github.io/2023/10/03/databricks-dbfs-and-other-filesystem/</guid><description>&lt;p>A summary of different file systems in Databricks.&lt;/p></description></item><item><title>Change Timezone in Databricks Spark</title><link>https://jdhao.github.io/2023/09/15/databricks-spark-change-timezone/</link><pubDate>Fri, 15 Sep 2023 20:12:22 +0200</pubDate><guid>https://jdhao.github.io/2023/09/15/databricks-spark-change-timezone/</guid><description>&lt;p>The Databricks cluster is using UTC as the default timezone.
So when you run some time-related code, the displayed time is not the local time, which is not ideal.
In this post, I want to share how to change the timezone setting for Databricks cluster.&lt;/p></description></item><item><title>Running/importing Python code/module in Databricks</title><link>https://jdhao.github.io/2023/06/06/databricks-run-import-code/</link><pubDate>Tue, 06 Jun 2023 21:37:45 +0200</pubDate><guid>https://jdhao.github.io/2023/06/06/databricks-run-import-code/</guid><description>&lt;p>Databricks is centered around notebooks for doing a lot of works.
As a result, it is often not obvious how to run or re-use code from another notebook or Python module.
In this post, I want to share how to do this in the Databricks.&lt;/p></description></item><item><title>How to get or set Databricks spark configuration</title><link>https://jdhao.github.io/2023/05/13/databricks-spark-get-set-conf/</link><pubDate>Sat, 13 May 2023 21:57:26 +0200</pubDate><guid>https://jdhao.github.io/2023/05/13/databricks-spark-get-set-conf/</guid><description>&lt;p>In this post, I summarize how to get or set a Databricks spark configuration/property.&lt;/p></description></item></channel></rss>